{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNXUeuUdd6ol"
      },
      "outputs": [],
      "source": [
        "%pip install patool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MqZPwc6eTG7"
      },
      "outputs": [],
      "source": [
        "!unrar x -kb -or -- /content/You.rar /content/\n",
        "!unrar x -kb -or -- '/content/Not You.rar'  /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oOxHeLcepcN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "directory = '/content/content/You'\n",
        "if not os.path.exists(directory):\n",
        "    print(f\"Directory '{directory}' does not exist.\")\n",
        "else:\n",
        "    num_files = sum(len(files) for _, _, files in os.walk(directory))\n",
        "    print(f\"Number of files in '{directory}': {num_files}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01vsmySCetES"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "directory = '/content/content/not You'\n",
        "if not os.path.exists(directory):\n",
        "    print(f\"Directory '{directory}' does not exist.\")\n",
        "else:\n",
        "    num_files = sum(len(files) for _, _, files in os.walk(directory))\n",
        "    print(f\"Number of files in '{directory}': {num_files}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eJ930-qjl6E"
      },
      "outputs": [],
      "source": [
        "!mkdir '/content/train'\n",
        "\n",
        "!mkdir '/content/train/You'\n",
        "!mkdir '/content/train/Not You'\n",
        "\n",
        "!mkdir '/content/test'\n",
        "\n",
        "!mkdir '/content/test/You'\n",
        "!mkdir '/content/test/Not You'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysSKRtZ8kZe1"
      },
      "outputs": [],
      "source": [
        "# first shuffle the files in '/content/content/You' and '/content/content/not You' and then\n",
        "# copy 70% of files in '/content/content/You' in '/content/train/You',\n",
        "# 70% of files in '/content/content/not You' in '/content/train/Not You',\n",
        "# 30% of files in '/content/content/You' in '/content/test/You',\n",
        "# 30% of files in '/content/content/not You' in '/content/test/Not You'\n",
        "\n",
        "import random\n",
        "\n",
        "you_dir = '/content/content/You'\n",
        "not_you_dir = '/content/content/not You'\n",
        "\n",
        "train_you_dir = '/content/train/You'\n",
        "train_not_you_dir = '/content/train/Not You'\n",
        "test_you_dir = '/content/test/You'\n",
        "test_not_you_dir = '/content/test/Not You'\n",
        "\n",
        "# Get list of files and shuffle them\n",
        "you_files = [os.path.join(you_dir, f) for f in os.listdir(you_dir) if os.path.isfile(os.path.join(you_dir, f))]\n",
        "not_you_files = [os.path.join(not_you_dir, f) for f in os.listdir(not_you_dir) if os.path.isfile(os.path.join(not_you_dir, f))]\n",
        "\n",
        "random.shuffle(you_files)\n",
        "random.shuffle(not_you_files)\n",
        "\n",
        "# Calculate split points\n",
        "you_train_split = int(0.7 * len(you_files))\n",
        "not_you_train_split = int(0.7 * len(not_you_files))\n",
        "\n",
        "# Split files into train and test sets\n",
        "you_train_files = you_files[:you_train_split]\n",
        "you_test_files = you_files[you_train_split:]\n",
        "\n",
        "not_you_train_files = not_you_files[:not_you_train_split]\n",
        "not_you_test_files = not_ishan_files[not_you_train_split:]\n",
        "\n",
        "# Copy files to train and test directories\n",
        "for f in you_train_files:\n",
        "    shutil.copy(f, train_you_dir)\n",
        "\n",
        "for f in you_test_files:\n",
        "    shutil.copy(f, test_you_dir)\n",
        "\n",
        "for f in not_you_train_files:\n",
        "    shutil.copy(f, train_not_you_dir)\n",
        "\n",
        "for f in not_you_test_files:\n",
        "    shutil.copy(f, test_not_you_dir)\n",
        "\n",
        "# Print number of files copied\n",
        "print(f\"Copied {len(you_train_files)} files to {train_you_dir}\")\n",
        "print(f\"Copied {len(you_test_files)} files to {test_you_dir}\")\n",
        "print(f\"Copied {len(not_you_train_files)} files to {train_not_you_dir}\")\n",
        "print(f\"Copied {len(not_you_test_files)} files to {test_not_you_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-51Hz1OlywE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "directory = '/content/train/You'\n",
        "if not os.path.exists(directory):\n",
        "    print(f\"Directory '{directory}' does not exist.\")\n",
        "else:\n",
        "    num_files = sum(len(files) for _, _, files in os.walk(directory))\n",
        "    print(f\"Number of files in '{directory}': {num_files}\")\n",
        "\n",
        "directory2 = '/content/train/Not You'\n",
        "if not os.path.exists(directory2):\n",
        "    print(f\"Directory '{directory2}' does not exist.\")\n",
        "else:\n",
        "    num_files = sum(len(files) for _, _, files in os.walk(directory2))\n",
        "    print(f\"Number of files in '{directory2}': {num_files}\")\n",
        "\n",
        "directory3 = '/content/test/You'\n",
        "if not os.path.exists(directory3):\n",
        "    print(f\"Directory '{directory3}' does not exist.\")\n",
        "else:\n",
        "    num_files = sum(len(files) for _, _, files in os.walk(directory3))\n",
        "    print(f\"Number of files in '{directory3}': {num_files}\")\n",
        "\n",
        "directory4 = '/content/test/Not You'\n",
        "if not os.path.exists(directory4):\n",
        "    print(f\"Directory '{directory4}' does not exist.\")\n",
        "else:\n",
        "    num_files = sum(len(files) for _, _, files in os.walk(directory4))\n",
        "    print(f\"Number of files in '{directory4}': {num_files}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsKaxbD6mPkp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ic_4NivpkEY"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rescale=1./255,\n",
        "    fill_mode='nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNYfFcs4qWiN"
      },
      "outputs": [],
      "source": [
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfiOmNSrqYez"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyTPHcrmqtj2"
      },
      "outputs": [],
      "source": [
        "#Generating train and test data\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/train',\n",
        "    target_size = (224, 224),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/test',\n",
        "    target_size = (224, 224),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INVVYNvdrKIV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBnONTwXrzTF"
      },
      "outputs": [],
      "source": [
        "#Making the CNN model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(3, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(6, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWkQcDMksAMk"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdMAXtRWsDwc"
      },
      "outputs": [],
      "source": [
        "# Training for 10 epochs\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPxvDaqDsKZ6"
      },
      "outputs": [],
      "source": [
        "#test one image and evaluate if the model is predicting correctly\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Choose a random image file from the test set for testing\n",
        "test_image_path = '/content/test/You/daylight_face_0.jpg' # Or test_not_ishan_files[0]\n",
        "\n",
        "# Load and preprocess the image\n",
        "img = load_img(test_image_path, target_size=(224, 224))\n",
        "img_array = img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array /= 255.  # Rescale\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Get the predicted class label\n",
        "predicted_class_index = int(round(prediction[0][0]))\n",
        "\n",
        "# Get the class labels from the generator (assuming binary classification)\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "# Determine the actual class label based on the file path\n",
        "actual_class_label = 'You' if 'Not' not in test_image_path else 'Not You'\n",
        "\n",
        "# Print the results\n",
        "print(f\"Testing image: {test_image_path}\")\n",
        "print(f\"Predicted class: {predicted_class_label}\")\n",
        "print(f\"Actual class: {actual_class_label}\")\n",
        "\n",
        "# Evaluate if the prediction is correct\n",
        "if predicted_class_label == actual_class_label:\n",
        "    print(\"Prediction is correct!\")\n",
        "else:\n",
        "    print(\"Prediction is incorrect.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hzg_wDAwxTOP"
      },
      "outputs": [],
      "source": [
        "# determine the accuracy of the model on the test set\n",
        "\n",
        "loss, accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
        "print(f\"Accuracy on the test set: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaRRMpvf0s3D"
      },
      "outputs": [],
      "source": [
        "model.save('MyModel.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laFRiNeV0xYT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
